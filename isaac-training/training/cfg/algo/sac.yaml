name: "sac"

feature_extractor:
  learning_rate: 5e-4
  dyn_obs_num: 5

# Stochastic Gaussian policy with Tanh-squash
actor:
  learning_rate: 3e-4
  action_limit: 2.0 # m/s

# Twin Q-value critics
critic:
  learning_rate: 3e-4
  hidden_sizes: [256, 256]
  tau: 0.005

# Entropy / temperature
temperature:
  init_alpha: 0.2
  target_entropy_scale: 1.0

# Training schedule
training_frame_num: 32 # frames per collector batch
batch_size: 1024
replay_capacity: 1000000
warmup_steps: 10000 # collect before learning starts
updates_per_step: 1 # gradient steps per env frame
